{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project path = /Users/guerramarj/github/scosy\n",
      "data path = /Users/guerramarj/github/scosy/dataset\n",
      "sys.path =\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/Users/guerramarj/anaconda3/envs/nlp/lib/python36.zip',\n",
       " '/Users/guerramarj/anaconda3/envs/nlp/lib/python3.6',\n",
       " '/Users/guerramarj/anaconda3/envs/nlp/lib/python3.6/lib-dynload',\n",
       " '/Users/guerramarj/.local/lib/python3.6/site-packages',\n",
       " '/Users/guerramarj/anaconda3/envs/nlp/lib/python3.6/site-packages',\n",
       " '/Users/guerramarj/anaconda3/envs/nlp/lib/python3.6/site-packages/cycler-0.10.0-py3.6.egg',\n",
       " '/Users/guerramarj/anaconda3/envs/nlp/lib/python3.6/site-packages/stanfordcorenlp-3.9.1.1-py3.6.egg',\n",
       " '/Users/guerramarj/anaconda3/envs/nlp/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/Users/guerramarj/.ipython',\n",
       " '/Users/guerramarj/github/scosy',\n",
       " '/Users/guerramarj/github/scosy/utils']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_name = 'scosy'\n",
    "project_path = Path(os.getcwd()).parent\n",
    "data_path = Path(project_path, 'dataset')\n",
    "\n",
    "# including the project folder and the utils folder\n",
    "if project_name not in ''.join(sys.path):\n",
    "    sys.path.extend([str(project_path), str(Path(project_path, 'utils'))])\n",
    "\n",
    "print('project path = {0}'.format(project_path))\n",
    "print('data path = {0}'.format(data_path))\n",
    "print('sys.path =')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "import csv\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from utils.parse import parse\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_roles(author_list):\n",
    "    \"\"\"\n",
    "    assign the chief author, ordinary author or principal investigator role to each author\n",
    "    :param author_list: a list of all the authors in the paper\n",
    "    :return: role_list: the authors' respective roles\n",
    "    \"\"\"\n",
    "\n",
    "    role_list = list()\n",
    "\n",
    "    for author_index in range(len(author_list)):\n",
    "        # Assign the author's rle\n",
    "        # if less than 2 authors then they are considered \"Chief Authors\"\n",
    "        if author_index <= 1 and author_index != len(author_list) - 1:\n",
    "            role_list.append('CA')\n",
    "        # If a person is after the first two authors and it'snt the last author its considered\n",
    "        # \"Ordinary Author\"\n",
    "        elif author_index > 1 and author_index != len(author_list) - 1:\n",
    "            role_list.append('OA')\n",
    "        # else \"Principal Investigator)\n",
    "        elif author_index == len(author_list) - 1:\n",
    "            role_list.append('PI')\n",
    "\n",
    "    return role_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_organization(affiliation_list):\n",
    "    \"\"\"\n",
    "    check and assign whether the authors belong to the CHOP or PENN organization.\n",
    "    :param affiliation_list: a list of all the affiliations of the authors\n",
    "    :return: chop_list, penn_list: lists with whether the author belong to the CHOP or PENN organization\n",
    "    \"\"\"\n",
    "    # initialize CHOP and PENN authors' organization to None = 0\n",
    "    chop_list = [0] * len(affiliation_list)\n",
    "    penn_list = [0] * len(affiliation_list)\n",
    "\n",
    "    for affiliation_index, affiliation in enumerate(affiliation_list):\n",
    "\n",
    "        sub_affiliation = affiliation.split(';')\n",
    "\n",
    "        for sa in sub_affiliation:\n",
    "            # Assign the author organization\n",
    "            if 'children' in sa.lower():\n",
    "                chop_list[affiliation_index] = 1\n",
    "                break\n",
    "            elif 'perelman' in sa.lower() or 'school of medicine' in sa.lower() or \\\n",
    "                 'pennsylvania' in affiliation.lower():\n",
    "                penn_list[affiliation_index] = 1\n",
    "                break\n",
    "\n",
    "    return chop_list, penn_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_descriptions():\n",
    "\n",
    "    # get the description, related to the MESH, in the 2017MeshTree.csv File\n",
    "    mesh_tree_file_object = Path(project_path, 'template/2017MeshTree.csv').open()\n",
    "    file_reader = csv.reader(mesh_tree_file_object, delimiter=',')\n",
    "    mesh_description_dict = dict()\n",
    "\n",
    "    for line in file_reader:\n",
    "        # split_line[0] = Number, split_line[1] = Description and split_line[2] = MESH\n",
    "        mesh_description_dict[line[2]] = line[1]\n",
    "    mesh_tree_file_object.close()\n",
    "\n",
    "    return mesh_description_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Entrez.email = \"guerramarj@email.chop.edu\"     # Always tell NCBI who you are\n",
    "handle = Entrez.esearch(db=\"pubmed\", retmax=50000, idtype=\"esearch\", mindate=\"2014/01/01\", maxdate=\"2020/08/21\",\n",
    "                        term=\"Perelman School of Medicine[Affiliation] OR Children's Hospital of \"\n",
    "                             \"Philadelphia[Affiliation] OR University of Pennsylvania School of \"\n",
    "                             \"Medicine[Affiliation] OR School of Medicine University of \"\n",
    "                             \"Pennsylvania[Affiliation]\",\n",
    "                        usehistory=\"y\")\n",
    "search_results = Entrez.read(handle)\n",
    "handle.close()\n",
    "# obtaining the list of relevant PMIDs\n",
    "id_list = search_results[\"IdList\"]\n",
    "\n",
    "# get all the record based on the PMIDs\n",
    "# logging.getLogger('regular.time').info('getting relevant authors\\' records based on PMIDs')\n",
    "fetch_records_handle = Entrez.efetch(db=\"pubmed\", id=id_list, retmode=\"text\", rettype=\"medline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_filename = \"results.xml\"\n",
    "with open(out_filename, \"w\") as out_handle:\n",
    "    out_handle.write(fetch_records_handle.read())\n",
    "fetch_records_handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_handle = open(out_filename)\n",
    "fetch_records = parse(handle=records_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing variables\n",
    "mesh_description_dict = obtain_descriptions()\n",
    "\n",
    "# contains all the metadata elements on the author level: PubMed unique Identifier number(PMID), AuthorID (as a\n",
    "# (CA) Ordinary Author (OA) or Principal Author (PA) and the author's affiliation\n",
    "author_record_df = pd.DataFrame(columns=['PMID', 'Author', 'author_chop', 'author_penn', 'Role',\n",
    "                                         'AffiliationInfo'])\n",
    "# contains all the metadata elements on the paper level: PubMed unique Identifier number(PMID), Title, Abstract,\n",
    "# Year, Month, AuthorList, SubjectList, date\n",
    "paper_record_df = pd.DataFrame(columns=['PMID', 'Title', 'Abstract', 'Year', 'Month', 'author_list',\n",
    "                                        'subject_list',\n",
    "                                        'date'])\n",
    "# contains all the metadata of the medical information: PubMed unique Identifier number(PMID), Primary Medical\n",
    "# Subject Header (MESH) and the description ID\n",
    "medical_record_df = pd.DataFrame(columns=['PMID', 'Desc', 'Primary_MeSH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 0 out of 0\n",
      "processing 1 out of 1\n",
      "processing 2 out of 2\n",
      "processing 3 out of 3\n",
      "processing 4 out of 4\n",
      "processing 5 out of 5\n",
      "processing 6 out of 6\n",
      "processing 7 out of 7\n",
      "processing 8 out of 8\n",
      "processing 9 out of 9\n",
      "processing 10 out of 10\n",
      "processing 11 out of 11\n",
      "processing 12 out of 12\n",
      "processing 13 out of 13\n",
      "processing 14 out of 14\n",
      "processing 15 out of 15\n",
      "processing 16 out of 16\n",
      "processing 17 out of 17\n",
      "processing 18 out of 18\n",
      "processing 19 out of 19\n",
      "processing 20 out of 20\n",
      "processing 21 out of 21\n",
      "processing 22 out of 22\n",
      "processing 23 out of 23\n",
      "processing 24 out of 24\n",
      "processing 25 out of 25\n",
      "processing 26 out of 26\n",
      "processing 27 out of 27\n",
      "processing 28 out of 28\n",
      "processing 29 out of 29\n",
      "processing 30 out of 30\n",
      "processing 31 out of 31\n",
      "processing 32 out of 32\n",
      "processing 33 out of 33\n",
      "processing 34 out of 34\n",
      "processing 35 out of 35\n",
      "processing 36 out of 36\n",
      "processing 37 out of 37\n",
      "processing 38 out of 38\n",
      "processing 39 out of 39\n",
      "processing 40 out of 40\n",
      "processing 41 out of 41\n",
      "processing 42 out of 42\n",
      "processing 43 out of 43\n",
      "processing 44 out of 44\n",
      "processing 45 out of 45\n",
      "processing 46 out of 46\n",
      "processing 47 out of 47\n",
      "processing 48 out of 48\n",
      "processing 49 out of 49\n",
      "processing 50 out of 50\n",
      "processing 51 out of 51\n",
      "processing 52 out of 52\n",
      "processing 53 out of 53\n",
      "processing 54 out of 54\n",
      "processing 55 out of 55\n",
      "processing 56 out of 56\n",
      "processing 57 out of 57\n",
      "processing 58 out of 58\n",
      "processing 59 out of 59\n",
      "processing 60 out of 60\n",
      "processing 61 out of 61\n",
      "processing 62 out of 62\n",
      "processing 63 out of 63\n",
      "processing 64 out of 64\n",
      "processing 65 out of 65\n",
      "processing 66 out of 66\n",
      "processing 67 out of 67\n",
      "processing 68 out of 68\n",
      "processing 69 out of 69\n",
      "processing 70 out of 70\n",
      "processing 71 out of 71\n",
      "processing 72 out of 72\n",
      "processing 73 out of 73\n",
      "processing 74 out of 74\n",
      "processing 75 out of 75\n",
      "processing 76 out of 76\n",
      "processing 77 out of 77\n",
      "processing 78 out of 78\n",
      "processing 79 out of 79\n",
      "processing 80 out of 80\n",
      "processing 81 out of 81\n",
      "processing 82 out of 82\n",
      "processing 83 out of 83\n",
      "processing 84 out of 84\n",
      "processing 85 out of 85\n",
      "processing 86 out of 86\n",
      "processing 87 out of 87\n",
      "processing 88 out of 88\n",
      "processing 89 out of 89\n",
      "processing 90 out of 90\n",
      "processing 91 out of 91\n",
      "processing 92 out of 92\n",
      "processing 93 out of 93\n",
      "processing 94 out of 94\n",
      "processing 95 out of 95\n",
      "processing 96 out of 96\n",
      "processing 97 out of 97\n",
      "processing 98 out of 98\n",
      "processing 99 out of 99\n",
      "processing 100 out of 100\n",
      "processing 101 out of 101\n",
      "processing 102 out of 102\n",
      "processing 103 out of 103\n",
      "processing 104 out of 104\n",
      "processing 105 out of 105\n",
      "processing 106 out of 106\n",
      "processing 107 out of 107\n",
      "processing 108 out of 108\n",
      "processing 109 out of 109\n",
      "processing 110 out of 110\n",
      "processing 111 out of 111\n",
      "processing 112 out of 112\n",
      "processing 113 out of 113\n",
      "processing 114 out of 114\n",
      "processing 115 out of 115\n",
      "processing 116 out of 116\n",
      "processing 117 out of 117\n",
      "processing 118 out of 118\n",
      "processing 119 out of 119\n",
      "processing 120 out of 120\n",
      "processing 121 out of 121\n",
      "processing 122 out of 122\n",
      "processing 123 out of 123\n",
      "processing 124 out of 124\n",
      "processing 125 out of 125\n",
      "processing 126 out of 126\n"
     ]
    }
   ],
   "source": [
    "title_list = list()\n",
    "abstract_list = list()\n",
    "total_records = len(fetch_records)\n",
    "\n",
    "try:\n",
    "    for record_index, record in enumerate(fetch_records):\n",
    "\n",
    "        print('processing {0} out of {1}'.format(record_index, total_records))\n",
    "\n",
    "        pmid = record.get('PMID')\n",
    "        title = record.get('TI')\n",
    "        abstract = record.get('AB')\n",
    "        authors = record.get('FAU')\n",
    "        affiliations = record.get('AD')\n",
    "        publication_type = record.get('PT')\n",
    "        mesh_term = record.get('MH')\n",
    "        date = record.get('EDAT')\n",
    "        year, month = date.split('/')[:2]\n",
    "\n",
    "    #     print('pmid = {0}'.format(pmid))\n",
    "    #     print('title = {0}'.format(title))\n",
    "    #     print('abstract = {0}'.format(abstract))\n",
    "    #     print('authors = {0}'.format(authors))\n",
    "    #     print('affiliations = {0}'.format(affiliations))\n",
    "    #     print('publication type = {0}'.format(publication_type))\n",
    "    #     print('mesh term = {0}'.format(mesh_term))\n",
    "    #     print('date created = {0}'.format(date))\n",
    "\n",
    "        if pmid is not None:\n",
    "            # assign the chief author, ordinary author or principal investigator role to each author\n",
    "            roles = assign_roles(authors)\n",
    "            # check and assign whether the authors belong to the CHOP or PENN organization\n",
    "            chop_organization, penn_organization = assign_organization(affiliations)\n",
    "\n",
    "            mesh_description = ''\n",
    "            if mesh_term is None:\n",
    "                mesh_term = ''\n",
    "            else:\n",
    "                mesh_description, term = convert_mesh_description(mesh_description_dict, mesh_term)\n",
    "                mesh_term = ';'.join(mesh_term)\n",
    "\n",
    "            # output information\n",
    "            if mesh_description:\n",
    "                row = pd.DataFrame([[pmid, term, mesh_description]], columns=['PMID', 'Primary_MeSH', 'Desc'])\n",
    "                medical_record_df = medical_record_df.append(row, ignore_index=True)\n",
    "\n",
    "            for author_index, organizations in enumerate(zip(chop_organization, penn_organization)):\n",
    "                # check if the author belongs to either CHOP or PENN\n",
    "                if 1 in organizations:\n",
    "                    row = pd.DataFrame([[pmid, authors[author_index], organizations[0], organizations[1],\n",
    "                                        roles[author_index], affiliations[author_index]]],\n",
    "                                       columns=['PMID', 'Author', 'author_chop', 'author_penn', 'Role',\n",
    "                                                'AffiliationInfo'])\n",
    "                    author_record_df = author_record_df.append(row, ignore_index=True)\n",
    "\n",
    "            authors = ';'.join(authors)\n",
    "\n",
    "            row = pd.DataFrame([[pmid, title, abstract, year, month, authors, mesh_term, date]],\n",
    "                               columns=['PMID', 'Title', 'Abstract', 'Year', 'Month', 'author_list', 'subject_list',\n",
    "                                        'date'])\n",
    "            paper_record_df = paper_record_df.append(row)\n",
    "\n",
    "            if title and abstract:\n",
    "                title_list.append(title)\n",
    "                abstract_list.append(abstract)\n",
    "except:\n",
    "    next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>author_list</th>\n",
       "      <th>subject_list</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PMID, Title, Abstract, Year, Month, author_list, subject_list, date]\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_record_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Author</th>\n",
       "      <th>author_chop</th>\n",
       "      <th>author_penn</th>\n",
       "      <th>Role</th>\n",
       "      <th>AffiliationInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PMID, Author, author_chop, author_penn, Role, AffiliationInfo]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_record_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Primary_MeSH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PMID, Desc, Primary_MeSH]\n",
       "Index: []"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medical_record_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
